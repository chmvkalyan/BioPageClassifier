{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FilenameCollection = collections.namedtuple('FilenameCollection', 'texts_path urls_path')\n",
    "\n",
    "# Seed for numpy randomizer\n",
    "SEED = 1337\n",
    "\n",
    "# Number of epochs for training\n",
    "EPOCH = 5\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Embedding\n",
    "EMBEDDING = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "\n",
    "# Tensor parameters\n",
    "# ---------------------------------------------------------\n",
    "# The name of the saved dataframe (helps with caching)\n",
    "KERAS_TRAINING_SET_NAME = \"training-data/keras_training_set.plk\"\n",
    "\n",
    "# The trained model name\n",
    "TENSOR_MODEL_NAME = \"bio-model\"\n",
    "\n",
    "# The filename in which the graphical picture of Keras NN will be saved\n",
    "TENSOR_MODEL_ARCH_PLOT_NAME = \"{}-arch-plot.png\".format(TENSOR_MODEL_NAME)\n",
    "\n",
    "# The filename in which the training history plot will be saved\n",
    "TENSOR_MODEL_HISTORY_PLOT_NAME = \"{}-history-plot.png\".format(TENSOR_MODEL_NAME)\n",
    "\n",
    "# Training data parameters\n",
    "# ---------------------------------------------------------\n",
    "# Positive training data locations\n",
    "POSITIVE_TRAINING_DATA_FILENAMES = FilenameCollection(\n",
    "    texts_path=\"training-data/bios.txt\", urls_path=\"training-data/urls.text\")\n",
    "\n",
    "# Negative training data locations\n",
    "NEGATIVE_TRAINING_DATA_FILENAMES = FilenameCollection(\n",
    "    texts_path=\"training-data/neg-texts.txt\", urls_path=\"training-data/neg-urls.txt\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"COMPRESSED\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Setting up variables\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    hub_layer = hub.KerasLayer(EMBEDDING, input_shape=[], dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_complex():\n",
    "    # Uses Keras Sequential Model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Hub Layer = Pretrained Model\n",
    "    model.add(hub.KerasLayer(EMBEDDING, input_shape=[], dtype=tf.string, trainable=True))\n",
    "\n",
    "    # Fine tune model\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with Binary Cross Entropy\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lstm_model(encoder):\n",
    "    # Uses Keras Sequential Model\n",
    "    model = tf.keras.Sequential()\n",
    "    if encoder:\n",
    "        model.add(encoder)\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))),\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu')),\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with Binary Cross Entropy\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model_name, model, test_dataset):\n",
    "    results = model.evaluate(test_dataset.batch(BATCH_SIZE), verbose=2)\n",
    "    for name, value in zip(model.metrics_names, results):\n",
    "        print(\"Model name: %s - %s: %.3f\" % (model_name, name, value))\n",
    "\n",
    "\n",
    "def run_tensor_trainer():\n",
    "    # Create training dataset\n",
    "    full_dataset, train_dataset, val_dataset, test_dataset = create_tensor_dataset(\n",
    "        KERAS_TRAINING_SET_NAME,\n",
    "        POSITIVE_TRAINING_DATA_FILENAMES.texts_path,\n",
    "        NEGATIVE_TRAINING_DATA_FILENAMES.texts_path)\n",
    "\n",
    "    # Encoding\n",
    "    encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=800)\n",
    "    encoder.adapt(full_dataset.map(lambda text,label: text))\n",
    "\n",
    "    # Create model and train\n",
    "    model = create_lstm_model(encoder=encoder)\n",
    "    plot_model(model, to_file=TENSOR_MODEL_ARCH_PLOT_NAME, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # cp = tf.keras.callbacks.ModelCheckpoint(filepath='best_weights.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # Early stopping\n",
    "    # es = tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset.shuffle(10000).batch(BATCH_SIZE),\n",
    "        epochs=EPOCH, validation_data=val_dataset.batch(BATCH_SIZE), verbose=1) # callbacks=[cp, es]\n",
    "\n",
    "    # model.load_weights('best_weights.hdf5')\n",
    "    evaluate_model(\"orig\", model, test_dataset)\n",
    "    plot_history(history, plot_filename=TENSOR_MODEL_HISTORY_PLOT_NAME)\n",
    "\n",
    "    # Saving the model\n",
    "    model.save(TENSOR_MODEL_NAME)\n",
    "    model = tf.keras.models.load_model(TENSOR_MODEL_NAME)\n",
    "\n",
    "    evaluate_model(\"loaded\", model, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define utilities\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entry Point\n",
    "run_tensor_trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Run\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}